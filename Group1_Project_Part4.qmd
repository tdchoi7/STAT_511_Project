---
title: "Project Part 4"
subtitle: "STAT 511"
author: "Moses Sanches, Shuyu Wang, Theodore Choi"
date: "`r Sys.Date()`"
format: 
  html:
    self-contained: true
    toc: true
    toc_float: true
    number-section: false
    highlight: tango
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| include: false
knitr::opts_chunk$set(echo = TRUE)

```

```{r}
#| message: false
#| warning: false
# Libraries we used
library(openintro)
library(tidyverse)
library(dplyr)
library(scales)
library(leaps)
library(MASS)
library(olsrr)
```

```{r}

# import data
filepath_2013 <- "./data/longevity Data Cleaned Version 2013 TFM.rds"

life_exp_pt4 <- readRDS(filepath_2013)

# show top rows
head(life_exp_pt4)

# life_exp_pt4[,2:21]

```

## Part A -- Preliminary Main effects model

### 1. Using the results from project part 3 as a starting point, determine the set of P-1 predictor variables under consideration.

```{r}

# find why alcohol has dense area in plot:
# count values
table(life_exp_pt4$alcohol_trnsfrm)[1]

```

> Based on examination of the alcohol, we can conclude that many countries reported 0.1 liters of pure alcohol consumed per capita

##### a. Make sure all variables have been transformed appropriately, as necessary.

##### b. You should combine levels of categorical variables at this step if necessary.

```{r}
# show unique values of columns
unique(life_exp_pt4$status)
unique(life_exp_pt4$continent)

# convert dummy variables within dataset
# https://statisticsglobe.com/convert-factor-to-dummy-variables-in-r
life_exp_pt4 <- data.frame(life_exp_pt4[ , ! colnames(life_exp_pt4) %in% "continent"],
                           model.matrix( ~ continent - 1, life_exp_pt4))

life_exp_pt4 <- data.frame(life_exp_pt4[ , ! colnames(life_exp_pt4) %in% "status"],
                           model.matrix( ~ status - 1, life_exp_pt4))

# remove first columns of the dummified factor variables
life_exp_pt4 <- life_exp_pt4[-25]
life_exp_pt4 <- life_exp_pt4[-20]

# check results
head(life_exp_pt4)
```

```{r}

# # impute nulls
# # https://stackoverflow.com/questions/20364450/find-names-of-columns-which-contain-missing-values
# cols_w_null <- names(which(colSums(is.na(life_exp_pt4)) > 0))
# null_range <- 1:length(cols_w_null)
# my_range <- 1:length(life_exp_pt4)
# 
# # setting NA = -1
# for (i in my_range)
#   {
#   life_exp_pt4[i] <-
#     rescale_max(life_exp_pt4[i])
# }
# 
# for (i in null_range)
#   {
#   life_exp_pt4[cols_w_null[i]][is.na(life_exp_pt4[cols_w_null[i]])] <- -1
#   # if setting to median instead:
#   #   life_exp_pt4[cols_w_null[i]][is.na(life_exp_pt4[cols_w_null[i]])] <-
# #     median(life_exp_pt4[cols_w_null[i]], na.rm = TRUE)
#   }
# 
# # check if columns contain any null values - sum should be 0 if no nulls
# # https://www.geeksforgeeks.org/how-to-check-missing-values-in-r-dataframe/
# sum(is.na(life_exp_pt4)) 

```

> From part 3: Thinness of Ages 1 to 19 and Thinness of Ages 5 to 9 seem to be quite correlated/possibly colinear (Corr: 0.925). Income Composition of Resources and Schooling also seem to be correlated/possibly colinear (Corr: 0.913). Percent Expenditure on Health as a Percentage of GDP and GDP also seem highly correlated/possibly colinear (Corr: 0.918). Infant Deaths and Under 5 Deaths seem to be quite correlated/possibly colinear (Corr: 0.997). Hepatitis B and Diptheria also seem to be correlated/possibly colinear (Corr: 0.711)

```{r}

# check for interactions
# compare thinness 1-19 to thinness 5-9
lm_thin_1 <- lm(life_exp_2013_response ~ thin_1_19_trnsfrm + thin_5_9_trnsfrm, data = life_exp_pt4)

summary(lm_thin_1)
anova(lm_thin_1)

lm_thin_2 <- lm(life_exp_2013_response ~ thin_5_9_trnsfrm + thin_1_19_trnsfrm, data = life_exp_pt4)

summary(lm_thin_2)
anova(lm_thin_2)

# to check if we should drop one of the thinness columns
lm_thin_59 <- lm(life_exp_2013_response ~ thin_5_9_trnsfrm, data = life_exp_pt4)


# checking reduced to full model
anova(lm_thin_59, lm_thin_2)

lm_thin_119 <- lm(life_exp_2013_response ~ thin_1_19_trnsfrm, data = life_exp_pt4)

# checking reduced to full model
anova(lm_thin_119, lm_thin_1)

```

```{r}

# compare schooling and income composition
lm_incsch_1 <- lm(life_exp_2013_response ~ inc_comp + school, data = life_exp_pt4)

summary(lm_incsch_1)
anova(lm_incsch_1)

lm_incsch_2 <- lm(life_exp_2013_response ~ school + inc_comp, data = life_exp_pt4)

summary(lm_incsch_2)
anova(lm_incsch_2)

# to check if we should drop school or inc_comp
lm_inc <- lm(life_exp_2013_response ~ inc_comp, data = life_exp_pt4)

anova(lm_inc, lm_incsch_1)

lm_school <- lm(life_exp_2013_response ~ school, data = life_exp_pt4)

anova(lm_school, lm_incsch_2)

```

```{r}

# # compare perc_exp and gdp
# lm_percgdp_1 <- lm(life_exp_2013_response ~ perc_exp_trnsfrm + gdp_trnsfrm, data = life_exp_pt4)
# 
# summary(lm_percgdp_1)
# anova(lm_percgdp_1)
# 
# lm_percgdp_2 <- lm(life_exp_2013_response ~ gdp_trnsfrm +  perc_exp_trnsfrm, data = life_exp_pt4)
# 
# summary(lm_percgdp_2)
# anova(lm_percgdp_2)
# 
# # check which column to drop
# lm_percexp <- lm(life_exp_2013_response ~ perc_exp_trnsfrm, data = life_exp_pt4)
# 
# anova(lm_percexp, lm_percgdp_1)
# 
# lm_gdp <- lm(life_exp_2013_response ~ gdp_trnsfrm, data = life_exp_pt4)
# 
# anova(lm_gdp, lm_percgdp_2)

```

```{r}

# compare infant deaths and under 5 deaths
lm_ifu5_1 <- lm(life_exp_2013_response ~ inf_death_trnsfrm + u5_deaths_trnsfrm, data = life_exp_pt4)

summary(lm_ifu5_1)
anova(lm_ifu5_1)

lm_ifu5_2 <- lm(life_exp_2013_response ~ u5_deaths_trnsfrm + inf_death_trnsfrm, data = life_exp_pt4)

summary(lm_ifu5_2)
anova(lm_ifu5_2)

# check which column to drop
lm_inf <- lm(life_exp_2013_response ~ inf_death_trnsfrm, data = life_exp_pt4)

anova(lm_inf, lm_ifu5_1)

lm_u5 <- lm(life_exp_2013_response ~ u5_deaths_trnsfrm, data = life_exp_pt4)

anova(lm_u5, lm_ifu5_2)

```

```{r}

# # compare hep b and diptheria
# lm_hepbdipth_1 <- lm(life_exp_2013_response ~ hep_b_trnsfrm + dipth_trnsfrm, data = life_exp_pt4)
# 
# summary(lm_hepbdipth_1)
# anova(lm_hepbdipth_1)
# 
# lm_hepbdipth_2 <- lm(life_exp_2013_response ~ dipth_trnsfrm + hep_b_trnsfrm, data = life_exp_pt4)
# 
# summary(lm_hepbdipth_2)
# anova(lm_hepbdipth_2)
# 
# # check which column to drop
# lm_hepb <- lm(life_exp_2013_response ~ hep_b_trnsfrm, data = life_exp_pt4)
# 
# anova(lm_hepb, lm_hepbdipth_1)
# 
# lm_dipth <- lm(life_exp_2013_response ~ dipth_trnsfrm, data = life_exp_pt4)
# 
# anova(lm_dipth, lm_hepbdipth_2)

```

> thin_1_19_trnsfrm and can be dropped from the model as it is the only one that had a high p-value

### 2. Fit a main effects (no interactions) model with the full set of P-1 predictors

```{r}

# drop thin_1_19_trnsfrm column
life_exp_pt4 <- life_exp_pt4[-8]

# fitting the full model
FullModel <- lm(life_exp_2013_response ~ .,
                   data = life_exp_pt4)

```

### 3. Show the summary table for this "preliminary main effects model"

```{r}

# checking model
summary(FullModel)

```

## Part B -- Model Selection Procedures

### 4. Conduct 2-3 model selection procedures (e.g. "best subsets" algorithm, stepwise forward/backward) to determine a few candidates for a "best" model

##### a. You do not need to include all the output in your report (i.e. use echo = FALSE and eval = FALSE in code chunks as necessary)

```{r}
#| echo: false

```{r}
# Stepwise Backwards/Forward/Both Regression
Base <- lm(life_exp_2013_response ~ 1, data = life_exp_pt4)
FullModel <- lm(life_exp_2013_response ~ ., data = life_exp_pt4)
```
```{r}
step(Base, scope = list(upper = FullModel, lower = Base), 
     direction = "forward", trace = FALSE)

step(FullModel, direction = "backward", trace = FALSE)

step(Base, scope = list(upper = FullModel, lower = Base), direction = "both", trace = TRUE)
```

### Best Subset Regression
# Cp_best <- leaps(x = life_exp_pt4[,2:21], y = life_exp_pt4$life_exp_2013_response,
#              method = "Cp", nbest = 1)
# 
# # Cp_best <- leaps(x = life_exp_2013[,2:3], y = life_exp_2013$longevity,
# #              method = "Cp", nbest = 1)
# 
# Cp_best <- data.frame(Cp_best$which,
#                       num_in_model = Cp_best$size - 1,
#                       p = Cp_best$size,
#                           Cp = Cp_best$Cp)
# Cp_best
# 
# ggplot(Cp_best, aes(x = num_in_model, y = Cp)) +
#   geom_point() +
#   theme_minimal()
  
# regfit.full <- regsubsets(life_exp_2013_response ~ ., data = life_exp_pt4)
# plot(regfit.full, scale = "Cp")


##### b. Report a few models that are candidates for "best" model and discuss their similarities and differences (e.g. what variables get included every time, which variables end up in some models but not others)

> From the stepwise foward and backward regression model as well as the best subset regression model, the adult mortality and alcohol trnsfrm variables are the only ones present in the three models constructed. This is good indication that they will be included to construct the best model. Variables tot_exp_trnsfrm, thin_5\_9_trnsfrm, and measles_trnsfrm were some that probably wont be used to decide the best model. This is due to them not being in all three models and they were eliminated in the backwards refression model. According to the Cp Best model, we will most likely choose from row 11 or 12 as those have a Cp close to the number of variables while having a relatively low number of variables used in the model

##### c. For any of these "best" models, do any indicator variables need to be added back in? I.e. did only some levels of a categorical variable make it in? Do the categories need to be collapsed or re-leveled in any way? Adapt the models as necessary.

> After looking at the models, it doesnt look like any indicator variables need to be added in or adjusted, since no catergorical variable levels are missing. Releveling would not do much as the only ordered categorical variable was the status column, but that column only had 2 options (developed, developing)

### 5. Among the variables deemed important, determine whether you will add any pairwise interactions to the model. This should be based off of substantive knowledge of the data & research question. For each interaction of interest, fit a full model (with the interactions) and the reduced model (without interactions) and conduct an F test to determine whether it should be included.

> Doesn't look like we will be doing pairwise interactions, since there doesnt seem to be variables correlated to each other.

```{r}
# Full/Reduced Models
# adult_mort_red <- lm(life_exp_2013_response ~ adult_mort * alcohol_trnsfrm, data = life_exp_pt4)
# 
# inf_death_trnsfrm_red <- lm(life_exp_2013_response ~ inf_death_trnsfrm * continent, data = life_exp_pt4)
# 
# measles_death_trnsfrm_red <- lm(life_exp_2013_response ~ measles_trnsfrm * continent, data = life_exp_pt4)
# 
# FullModel <- lm(life_exp_2013_response ~ ., data = life_exp_pt4)
# 
# adult_mort_red 
# inf_death_trnsfrm_red
# measles_death_trnsfrm_red
# FullModel
# 
# anova(measles_death_trnsfrm_red,FullModel)
# anova(adult_mort_red,FullModel)
# anova(inf_death_trnsfrm_red,FullModel)
```
> Since the F statistics is greater than the p value, we will not be adding adult mortality and alcohol, infant deaths and continent, or measles and continent to the model.
```

### 6. Based on your results in Step 5 & 6 and substantive knowledge about the dataset, select a preliminary "best" model. Show the summary output for this model and write out the regression equation.

```{r}
m1 <- lm(life_exp_2013_response ~ adult_mort + alcohol_trnsfrm, data = life_exp_pt4)
summary(m1)
anova(m1)
```
> Y = 75.217382 - 0.048497 * X1 + 8.101951 * X2
> 
## Part C -- Preliminary summary

### Provide a brief (1 paragraph) summary of your findings so far. Some things to comment on:

##### • What variables appear to be associated with your outcome of interest?

##### • How much variation in Y does your set of predictor variables explain?

##### • Interpret some of the parameters of interest

>According to our regression models, adult mortality and alcohol trnsfrm variables are the variables that are most asscociated with out outcome of interest. Our set of predictor variales explain 0.6182 variation in Y. Accoring to the models we build, most of what explained in school can not be explained in inc_comp as well since SSR of school and school|inc_comp are similar to each other and vice versa. It seems there's a big difference of SSR of GDP and GDP|perc_exp, so one of them should be able to be dropped from the model. The variables we chose at last are adult mortality and alcohol trnsfrm, the SSR does have big difference but each of them is still a large number, so none of them should be dropped.

```{r}
# # Exporting Dataset
# life_exp_pt4_fact <- life_exp_pt4[,c('continent.f', 'status.f')]
# 
# # assign transformed columns to variable
# life_exp_pt4_tfm <- cbind(life_exp_pt4_tfm_num, life_exp_pt4_fact)
# 
# # rearrange data
# life_exp_pt4_tfm <- life_exp_pt4_tfm[, c(19, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,
#                                            12, 13, 14, 15, 16, 17, 18, 20, 21)]
# 
# # output dataframe
# head(life_exp_pt4_tfm)
# 
# # assign filepaths to variables
# filepath_2013_tfm <- "./data/longevity Data Cleaned Version 2013 TFM.rds"
# 
# # save to csv
# saveRDS(life_exp_pt4_tfm, filepath_2013_tfm)
```
